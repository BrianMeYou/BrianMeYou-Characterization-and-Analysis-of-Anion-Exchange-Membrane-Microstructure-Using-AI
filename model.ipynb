{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:00.892057Z","iopub.status.busy":"2024-03-30T11:27:00.891669Z","iopub.status.idle":"2024-03-30T11:27:06.020305Z","shell.execute_reply":"2024-03-30T11:27:06.019483Z","shell.execute_reply.started":"2024-03-30T11:27:00.892020Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from collections import OrderedDict\n","from efficientnet_pytorch import EfficientNet\n","from efficientnet_pytorch.utils import url_map, url_map_advprop, get_model_params\n","import functools\n","import torch.utils.model_zoo as model_zoo\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset as BaseDataset\n","from typing import Optional, Union, List\n","import re\n","import os\n","import cv2\n","import matplotlib.pyplot as plt\n","import albumentations as albu\n","import sys\n","from tqdm import tqdm as tqdm\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.021838Z","iopub.status.busy":"2024-03-30T11:27:06.021419Z","iopub.status.idle":"2024-03-30T11:27:06.027324Z","shell.execute_reply":"2024-03-30T11:27:06.026481Z","shell.execute_reply.started":"2024-03-30T11:27:06.021804Z"},"trusted":true},"outputs":[],"source":["DATA_DIR = '/input/afm-check'\n","\n","x_train_dir = os.path.join(DATA_DIR, 'train')\n","y_train_dir = os.path.join(DATA_DIR, 'train_label')\n","\n","x_valid_dir = os.path.join(DATA_DIR, 'validation')\n","y_valid_dir = os.path.join(DATA_DIR, 'validation_label')\n","\n","x_test_dir = os.path.join(DATA_DIR, 'test')\n","y_test_dir = os.path.join(DATA_DIR, 'test_label')"]},{"cell_type":"markdown","metadata":{},"source":["Encoder Modules"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.030480Z","iopub.status.busy":"2024-03-30T11:27:06.030132Z","iopub.status.idle":"2024-03-30T11:27:06.065287Z","shell.execute_reply":"2024-03-30T11:27:06.064449Z","shell.execute_reply.started":"2024-03-30T11:27:06.030448Z"},"trusted":true},"outputs":[],"source":["try:\n","    from inplace_abn import InPlaceABN\n","except ImportError:\n","    InPlaceABN = None\n","\n","class PreActivatedConv2dReLU(nn.Sequential):\n","    def __init__(\n","            self,\n","            in_channels, \n","            out_channels,\n","            kernel_size,\n","            padding=0,\n","            stride=1,\n","            use_batchnorm=True,\n","    ):\n","\n","        if use_batchnorm == \"inplace\" and InPlaceABN is None:\n","            raise RuntimeError(\n","                \"In order to use `use_batchnorm='inplace'` inplace_abn package must be installed. \"\n","                + \"To install see: https://github.com/mapillary/inplace_abn\"\n","            )\n","        if use_batchnorm == \"inplace\":\n","            bn = InPlaceABN(out_channels, activation=\"leaky_relu\", activation_param=0.0)\n","            relu = nn.Identity()\n","        elif use_batchnorm and use_batchnorm != \"inplace\":\n","            bn = nn.BatchNorm2d(out_channels)\n","        else:\n","            bn = nn.Identity()\n","\n","        relu = nn.ReLU(inplace=True)\n","\n","        conv = nn.Conv2d(\n","            in_channels,\n","            out_channels,\n","            kernel_size,\n","            stride=stride,\n","            padding=padding,\n","            bias=not (use_batchnorm),\n","        )\n","        super(PreActivatedConv2dReLU, self).__init__(conv, bn, relu)\n","\n","class Conv2dReLU(nn.Sequential):\n","    def __init__(\n","            self,\n","            in_channels,\n","            out_channels,\n","            kernel_size,\n","            padding=0,\n","            stride=1,\n","            use_batchnorm=True,\n","    ):\n","\n","        if use_batchnorm == \"inplace\" and InPlaceABN is None:\n","            raise RuntimeError(\n","                \"In order to use `use_batchnorm='inplace'` inplace_abn package must be installed. \"\n","                + \"To install see: https://github.com/mapillary/inplace_abn\"\n","            )\n","\n","        conv = nn.Conv2d(\n","            in_channels,\n","            out_channels,\n","            kernel_size,\n","            stride=stride,\n","            padding=padding,\n","            bias=not (use_batchnorm),\n","        )\n","        relu = nn.ReLU(inplace=True)\n","\n","        if use_batchnorm == \"inplace\":\n","            bn = InPlaceABN(out_channels, activation=\"leaky_relu\", activation_param=0.0)\n","            relu = nn.Identity()\n","        elif use_batchnorm and use_batchnorm != \"inplace\":\n","            bn = nn.BatchNorm2d(out_channels)\n","        else:\n","            bn = nn.Identity()\n","\n","        super(Conv2dReLU, self).__init__(conv, bn, relu)\n","\n","class DepthWiseConv2d(nn.Conv2d):\n","    def __init__(self, channels, kernel_size=3, stride=1):\n","        super().__init__(channels, channels, kernel_size, stride=stride, padding=kernel_size//2, groups=channels)\n","\n","class PointWiseConv2d(nn.Conv2d):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__(in_channels, out_channels, kernel_size=1, stride=1)\n","\n","class SEModule(nn.Module):\n","    def __init__(self, in_channels, reduction=16):\n","        super().__init__()\n","        self.cSE = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(1),\n","            nn.Conv2d(in_channels, in_channels // reduction, 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels // reduction, in_channels, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        return x * self.cSE(x)\n","\n","class sSEModule(nn.Module):\n","    def __init__(self, in_channels):\n","        super().__init__()\n","        self.sSE = nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid())\n","\n","    def forward(self, x):\n","        return x * self.sSE(x)\n","\n","class SCSEModule(nn.Module):\n","    def __init__(self, in_channels, reduction=16):\n","        super().__init__()\n","        self.cSE = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(1),\n","            nn.Conv2d(in_channels, in_channels // reduction, 1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_channels // reduction, in_channels, 1),\n","            nn.Sigmoid(),\n","        )\n","        self.sSE = nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid())\n","\n","    def forward(self, x):\n","        return x * self.cSE(x) + x * self.sSE(x)\n","\n","class ArgMax(nn.Module):\n","\n","    def __init__(self, dim=None):\n","        super().__init__()\n","        self.dim = dim\n","\n","    def forward(self, x):\n","        return torch.argmax(x, dim=self.dim)\n","\n","\n","class Activation(nn.Module):\n","\n","    def __init__(self, name, **params):\n","\n","        super().__init__()\n","\n","        if name is None or name == 'identity':\n","            self.activation = nn.Identity(**params)\n","        elif name == 'sigmoid':\n","            self.activation = nn.Sigmoid()\n","        elif name == 'softmax2d':\n","            self.activation = nn.Softmax(dim=1, **params)\n","        elif name == 'softmax':\n","            self.activation = nn.Softmax(**params)\n","        elif name == 'logsoftmax':\n","            self.activation = nn.LogSoftmax(**params)\n","        elif name == 'tanh':\n","            self.activation = nn.Tanh()\n","        elif name == 'argmax':\n","            self.activation = ArgMax(**params)\n","        elif name == 'argmax2d':\n","            self.activation = ArgMax(dim=1, **params)\n","        elif callable(name):\n","            self.activation = name(**params)\n","        else:\n","            raise ValueError('Activation should be callable/sigmoid/softmax/logsoftmax/tanh/None; got {}'.format(name))\n","\n","    def forward(self, x):\n","        return self.activation(x)\n","\n","\n","class Attention(nn.Module):\n","\n","    def __init__(self, name, **params):\n","        super().__init__()\n","\n","        if name is None:\n","            self.attention = nn.Identity(**params)\n","        elif name == 'scse':\n","            self.attention = SCSEModule(**params)\n","        elif name == 'se':\n","            self.attention = SEModule(**params)\n","        else:\n","            raise ValueError(\"Attention {} is not implemented\".format(name))\n","\n","    def forward(self, x):\n","        return self.attention(x)\n","\n","class Flatten(nn.Module):\n","    def forward(self, x):\n","        return x.view(x.shape[0], -1)"]},{"cell_type":"markdown","metadata":{},"source":["Decoder Modules"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.066606Z","iopub.status.busy":"2024-03-30T11:27:06.066351Z","iopub.status.idle":"2024-03-30T11:27:06.083802Z","shell.execute_reply":"2024-03-30T11:27:06.083014Z","shell.execute_reply.started":"2024-03-30T11:27:06.066584Z"},"trusted":true},"outputs":[],"source":["class DecoderBlock(nn.Module):\n","    def __init__(\n","            self,\n","            in_channels,\n","            skip_channels,\n","            out_channels,\n","            use_batchnorm=True,\n","            attention_type=None,\n","    ):\n","        super().__init__()\n","\n","        self.conv1 = Conv2dReLU(\n","            in_channels + skip_channels,\n","            out_channels,\n","            kernel_size=3,\n","            padding=1,\n","            use_batchnorm=use_batchnorm,\n","        )\n","        self.attention1 = Attention(attention_type, in_channels=in_channels + skip_channels)\n","        self.conv2 = Conv2dReLU(\n","            out_channels,\n","            out_channels,\n","            kernel_size=3,\n","            padding=1,\n","            use_batchnorm=use_batchnorm,\n","        )\n","        self.attention2 = Attention(attention_type, in_channels=out_channels)\n","\n","    def forward(self, x, skip=None):\n","        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n","        if skip is not None:\n","            x = torch.cat([x, skip], dim=1)\n","            x = self.attention1(x)\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.attention2(x)\n","        return x\n","\n","\n","class CenterBlock(nn.Sequential):\n","    def __init__(self, in_channels, out_channels, use_batchnorm=True):\n","        conv1 = Conv2dReLU(\n","            in_channels,\n","            out_channels,\n","            kernel_size=3,\n","            padding=1,\n","            use_batchnorm=use_batchnorm,\n","        )\n","        conv2 = Conv2dReLU(\n","            out_channels,\n","            out_channels,\n","            kernel_size=3,\n","            padding=1,\n","            use_batchnorm=use_batchnorm,\n","        )\n","        super().__init__(conv1, conv2)\n","\n","\n","class UnetDecoder(nn.Module):\n","    def __init__(\n","            self,\n","            encoder_channels,\n","            decoder_channels,\n","            n_blocks=5,\n","            use_batchnorm=True,\n","            attention_type=None,\n","            center=False,\n","    ):\n","        super().__init__()\n","\n","        if n_blocks != len(decoder_channels):\n","            raise ValueError(\n","                \"Model depth is {}, but you provide `decoder_channels` for {} blocks.\".format(\n","                    n_blocks, len(decoder_channels)\n","                )\n","            )\n","\n","        encoder_channels = encoder_channels[1:] \n","        encoder_channels = encoder_channels[::-1] \n","\n","        # computing blocks input and output channels\n","        head_channels = encoder_channels[0]\n","        in_channels = [head_channels] + list(decoder_channels[:-1])\n","        skip_channels = list(encoder_channels[1:]) + [0]\n","        out_channels = decoder_channels\n","\n","        if center:\n","            self.center = CenterBlock(\n","                head_channels, head_channels, use_batchnorm=use_batchnorm\n","            )\n","        else:\n","            self.center = nn.Identity()\n","\n","        # combine decoder keyword arguments\n","        kwargs = dict(use_batchnorm=use_batchnorm, attention_type=attention_type)\n","        blocks = [\n","            DecoderBlock(in_ch, skip_ch, out_ch, **kwargs)\n","            for in_ch, skip_ch, out_ch in zip(in_channels, skip_channels, out_channels)\n","        ]\n","        self.blocks = nn.ModuleList(blocks)\n","\n","    def forward(self, *features):\n","\n","        features = features[1:]    # remove first skip with same spatial resolution\n","        features = features[::-1]  # reverse channels to start from head of encoder\n","\n","        head = features[0]\n","        skips = features[1:]\n","\n","        x = self.center(head)\n","        for i, decoder_block in enumerate(self.blocks):\n","            skip = skips[i] if i < len(skips) else None\n","            x = decoder_block(x, skip)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.085105Z","iopub.status.busy":"2024-03-30T11:27:06.084795Z","iopub.status.idle":"2024-03-30T11:27:06.097848Z","shell.execute_reply":"2024-03-30T11:27:06.097089Z","shell.execute_reply.started":"2024-03-30T11:27:06.085083Z"},"trusted":true},"outputs":[],"source":["def patch_first_conv(model, in_channels):\n","    # get first conv\n","    for module in model.modules():\n","        if isinstance(module, nn.Conv2d):\n","            break\n","\n","    # change input channels for first conv\n","    module.in_channels = in_channels\n","    weight = module.weight.detach()\n","    reset = False\n","\n","    if in_channels == 1:\n","        weight = weight.sum(1, keepdim=True)\n","    elif in_channels == 2:\n","        weight = weight[:, :2] * (3.0 / 2.0)\n","    else:\n","        reset = True\n","        weight = torch.Tensor(\n","            module.out_channels,\n","            module.in_channels // module.groups,\n","            *module.kernel_size\n","        )\n","\n","    module.weight = nn.parameter.Parameter(weight)\n","    if reset:\n","        module.reset_parameters()\n","\n","\n","def replace_strides_with_dilation(module, dilation_rate):\n","    for mod in module.modules():\n","        if isinstance(mod, nn.Conv2d):\n","            mod.stride = (1, 1)\n","            mod.dilation = (dilation_rate, dilation_rate)\n","            kh, kw = mod.kernel_size\n","            mod.padding = ((kh // 2) * dilation_rate, (kh // 2) * dilation_rate)\n","\n","            # Kostyl for EfficientNet\n","            if hasattr(mod, \"static_padding\"):\n","                mod.static_padding = nn.Identity()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.099363Z","iopub.status.busy":"2024-03-30T11:27:06.099057Z","iopub.status.idle":"2024-03-30T11:27:06.112174Z","shell.execute_reply":"2024-03-30T11:27:06.111362Z","shell.execute_reply.started":"2024-03-30T11:27:06.099335Z"},"trusted":true},"outputs":[],"source":["class EncoderMixin:\n","    @property\n","    def out_channels(self):\n","        return self._out_channels[: self._depth + 1]\n","\n","    def set_in_channels(self, in_channels):\n","        if in_channels == 3:\n","            return\n","\n","        self._in_channels = in_channels\n","        if self._out_channels[0] == 3:\n","            self._out_channels = tuple([in_channels] + list(self._out_channels)[1:])\n","\n","        patch_first_conv(model=self, in_channels=in_channels)\n","\n","    def get_stages(self):\n","        raise NotImplementedError\n","\n","    def make_dilated(self, stage_list, dilation_list):\n","        stages = self.get_stages()\n","        for stage_indx, dilation_rate in zip(stage_list, dilation_list):\n","            replace_strides_with_dilation(\n","                module=stages[stage_indx],\n","                dilation_rate=dilation_rate,\n","            )"]},{"cell_type":"markdown","metadata":{},"source":["Encoders:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.113836Z","iopub.status.busy":"2024-03-30T11:27:06.113587Z","iopub.status.idle":"2024-03-30T11:27:06.135243Z","shell.execute_reply":"2024-03-30T11:27:06.134535Z","shell.execute_reply.started":"2024-03-30T11:27:06.113806Z"},"trusted":true},"outputs":[],"source":["class EfficientNetEncoder(EfficientNet, EncoderMixin):\n","    def __init__(self, stage_idxs, out_channels, model_name, depth=5):\n","\n","        blocks_args, global_params = get_model_params(model_name, override_params=None)\n","        super().__init__(blocks_args, global_params)\n","\n","        self._stage_idxs = stage_idxs\n","        self._out_channels = out_channels\n","        self._depth = depth\n","        self._in_channels = 3\n","\n","        del self._fc\n","\n","    def get_stages(self):\n","        return [\n","            nn.Identity(),\n","            nn.Sequential(self._conv_stem, self._bn0, self._swish),\n","            self._blocks[:self._stage_idxs[0]],\n","            self._blocks[self._stage_idxs[0]:self._stage_idxs[1]],\n","            self._blocks[self._stage_idxs[1]:self._stage_idxs[2]],\n","            self._blocks[self._stage_idxs[2]:],\n","        ]\n","\n","    def forward(self, x):\n","        stages = self.get_stages()\n","\n","        block_number = 0.\n","        drop_connect_rate = self._global_params.drop_connect_rate\n","\n","        features = []\n","        for i in range(self._depth + 1):\n","\n","            # Identity and Sequential stages\n","            if i < 2:\n","                x = stages[i](x)\n","\n","            # Block stages need drop_connect rate\n","            else:\n","                for module in stages[i]:\n","                    drop_connect = drop_connect_rate * block_number / len(self._blocks)\n","                    block_number += 1.\n","                    x = module(x, drop_connect)\n","\n","            features.append(x)\n","\n","        return features\n","\n","    def load_state_dict(self, state_dict, **kwargs):\n","        state_dict.pop(\"_fc.bias\")\n","        state_dict.pop(\"_fc.weight\")\n","        super().load_state_dict(state_dict, **kwargs)\n","\n","\n","def  _get_pretrained_settings(encoder):\n","    pretrained_settings = {\n","        \"imagenet\": {\n","            \"mean\": [0.485, 0.456, 0.406],\n","            \"std\": [0.229, 0.224, 0.225],\n","            \"url\": url_map[encoder],\n","            \"input_space\": \"RGB\",\n","            \"input_range\": [0, 1],\n","        },\n","        \"advprop\": {\n","            \"mean\": [0.5, 0.5, 0.5],\n","            \"std\": [0.5, 0.5, 0.5],\n","            \"url\": url_map_advprop[encoder],\n","            \"input_space\": \"RGB\",\n","            \"input_range\": [0, 1],\n","        }\n","    }\n","    return pretrained_settings\n","\n","\n","efficient_net_encoders = {\n","    \"efficientnet-b0\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b0\"),\n","        \"params\": {\n","            \"out_channels\": (3, 32, 24, 40, 112, 320),\n","            \"stage_idxs\": (3, 5, 9, 16),\n","            \"model_name\": \"efficientnet-b0\",\n","        },\n","    },\n","    \"efficientnet-b1\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b1\"),\n","        \"params\": {\n","            \"out_channels\": (3, 32, 24, 40, 112, 320),\n","            \"stage_idxs\": (5, 8, 16, 23),\n","            \"model_name\": \"efficientnet-b1\",\n","        },\n","    },\n","    \"efficientnet-b2\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b2\"),\n","        \"params\": {\n","            \"out_channels\": (3, 32, 24, 48, 120, 352),\n","            \"stage_idxs\": (5, 8, 16, 23),\n","            \"model_name\": \"efficientnet-b2\",\n","        },\n","    },\n","    \"efficientnet-b3\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b3\"),\n","        \"params\": {\n","            \"out_channels\": (3, 40, 32, 48, 136, 384),\n","            \"stage_idxs\": (5, 8, 18, 26),\n","            \"model_name\": \"efficientnet-b3\",\n","        },\n","    },\n","    \"efficientnet-b4\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b4\"),\n","        \"params\": {\n","            \"out_channels\": (3, 48, 32, 56, 160, 448),\n","            \"stage_idxs\": (6, 10, 22, 32),\n","            \"model_name\": \"efficientnet-b4\",\n","        },\n","    },\n","    \"efficientnet-b5\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b5\"),\n","        \"params\": {\n","            \"out_channels\": (3, 48, 40, 64, 176, 512),\n","            \"stage_idxs\": (8, 13, 27, 39),\n","            \"model_name\": \"efficientnet-b5\",\n","        },\n","    },\n","    \"efficientnet-b6\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b6\"),\n","        \"params\": {\n","            \"out_channels\": (3, 56, 40, 72, 200, 576),\n","            \"stage_idxs\": (9, 15, 31, 45),\n","            \"model_name\": \"efficientnet-b6\",\n","        },\n","    },\n","    \"efficientnet-b7\": {\n","        \"encoder\": EfficientNetEncoder,\n","        \"pretrained_settings\": _get_pretrained_settings(\"efficientnet-b7\"),\n","        \"params\": {\n","            \"out_channels\": (3, 64, 48, 80, 224, 640),\n","            \"stage_idxs\": (11, 18, 38, 55),\n","            \"model_name\": \"efficientnet-b7\",\n","        },\n","    },\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.136285Z","iopub.status.busy":"2024-03-30T11:27:06.136055Z","iopub.status.idle":"2024-03-30T11:27:06.148793Z","shell.execute_reply":"2024-03-30T11:27:06.147896Z","shell.execute_reply.started":"2024-03-30T11:27:06.136257Z"},"trusted":true},"outputs":[],"source":["def preprocess_input(x, mean=None, std=None, input_space=\"RGB\", input_range=None, **kwargs):\n","\n","    if input_space == \"BGR\":\n","        x = x[..., ::-1].copy()\n","\n","    if input_range is not None:\n","        if x.max() > 1 and input_range[1] == 1:\n","            x = x / 255.0\n","\n","    if mean is not None:\n","        mean = np.array(mean)\n","        x = x - mean\n","\n","    if std is not None:\n","        std = np.array(std)\n","        x = x / std\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.153433Z","iopub.status.busy":"2024-03-30T11:27:06.152977Z","iopub.status.idle":"2024-03-30T11:27:06.164064Z","shell.execute_reply":"2024-03-30T11:27:06.163228Z","shell.execute_reply.started":"2024-03-30T11:27:06.153409Z"},"trusted":true},"outputs":[],"source":["def get_encoder(name, in_channels=3, depth=5, weights=None):\n","\n","    try:\n","        Encoder = encoders[name][\"encoder\"]\n","    except KeyError:\n","        raise KeyError(\"Wrong encoder name `{}`, supported encoders: {}\".format(name, list(encoders.keys())))\n","\n","    params = encoders[name][\"params\"]\n","    params.update(depth=depth)\n","    encoder = Encoder(**params)\n","\n","    if weights is not None:\n","        try:\n","            settings = encoders[name][\"pretrained_settings\"][weights]\n","        except KeyError:\n","            raise KeyError(\"Wrong pretrained weights `{}` for encoder `{}`. Available options are: {}\".format(\n","                weights, name, list(encoders[name][\"pretrained_settings\"].keys()),\n","            ))\n","        encoder.load_state_dict(model_zoo.load_url(settings[\"url\"]))\n","\n","    encoder.set_in_channels(in_channels)\n","\n","    return encoder\n","\n","\n","def get_encoder_names():\n","    return list(encoders.keys())\n","\n","\n","def get_preprocessing_params(encoder_name, pretrained=\"imagenet\"):\n","    settings = encoders[encoder_name][\"pretrained_settings\"]\n","\n","    if pretrained not in settings.keys():\n","        raise ValueError(\"Available pretrained options {}\".format(settings.keys()))\n","\n","    formatted_settings = {}\n","    formatted_settings[\"input_space\"] = settings[pretrained].get(\"input_space\")\n","    formatted_settings[\"input_range\"] = settings[pretrained].get(\"input_range\")\n","    formatted_settings[\"mean\"] = settings[pretrained].get(\"mean\")\n","    formatted_settings[\"std\"] = settings[pretrained].get(\"std\")\n","    return formatted_settings\n","\n","\n","def get_preprocessing_fn(encoder_name, pretrained=\"imagenet\"):\n","    params = get_preprocessing_params(encoder_name, pretrained=pretrained)\n","    return functools.partial(preprocess_input, **params)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.165404Z","iopub.status.busy":"2024-03-30T11:27:06.165093Z","iopub.status.idle":"2024-03-30T11:27:06.177644Z","shell.execute_reply":"2024-03-30T11:27:06.176875Z","shell.execute_reply.started":"2024-03-30T11:27:06.165373Z"},"trusted":true},"outputs":[],"source":["def initialize_decoder(module):\n","    for m in module.modules():\n","\n","        if isinstance(m, nn.Conv2d):\n","            nn.init.kaiming_uniform_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n","            if m.bias is not None:\n","                nn.init.constant_(m.bias, 0)\n","\n","        elif isinstance(m, nn.BatchNorm2d):\n","            nn.init.constant_(m.weight, 1)\n","            nn.init.constant_(m.bias, 0)\n","\n","        elif isinstance(m, nn.Linear):\n","            nn.init.xavier_uniform_(m.weight)\n","            if m.bias is not None:\n","                nn.init.constant_(m.bias, 0)\n","\n","\n","def initialize_head(module):\n","    for m in module.modules():\n","        if isinstance(m, (nn.Linear, nn.Conv2d)):\n","            nn.init.xavier_uniform_(m.weight)\n","            if m.bias is not None:\n","                nn.init.constant_(m.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.178957Z","iopub.status.busy":"2024-03-30T11:27:06.178681Z","iopub.status.idle":"2024-03-30T11:27:06.191549Z","shell.execute_reply":"2024-03-30T11:27:06.190834Z","shell.execute_reply.started":"2024-03-30T11:27:06.178935Z"},"trusted":true},"outputs":[],"source":["class SegmentationModel(torch.nn.Module):\n","\n","    def initialize(self):\n","        initialize_decoder(self.decoder)\n","        initialize_head(self.segmentation_head)\n","        if self.classification_head is not None:\n","            initialize_head(self.classification_head)\n","\n","    def forward(self, x):\n","        \"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\n","        features = self.encoder(x)\n","        decoder_output = self.decoder(*features)\n","\n","        masks = self.segmentation_head(decoder_output)\n","\n","        if self.classification_head is not None:\n","            labels = self.classification_head(features[-1])\n","            return masks, labels\n","\n","        return masks\n","\n","    def predict(self, x):\n","        if self.training:\n","            self.eval()\n","\n","        with torch.no_grad():\n","            x = self.forward(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.193286Z","iopub.status.busy":"2024-03-30T11:27:06.192725Z","iopub.status.idle":"2024-03-30T11:27:06.203406Z","shell.execute_reply":"2024-03-30T11:27:06.202720Z","shell.execute_reply.started":"2024-03-30T11:27:06.193256Z"},"trusted":true},"outputs":[],"source":["class SegmentationHead(nn.Sequential):\n","\n","    def __init__(self, in_channels, out_channels, kernel_size=3, activation=None, upsampling=1):\n","        conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n","        upsampling = nn.UpsamplingBilinear2d(scale_factor=upsampling) if upsampling > 1 else nn.Identity()\n","        activation = Activation(activation)\n","        super().__init__(conv2d, upsampling, activation)\n","\n","\n","class ClassificationHead(nn.Sequential):\n","\n","    def __init__(self, in_channels, classes, pooling=\"avg\", dropout=0.2, activation=None):\n","        if pooling not in (\"max\", \"avg\"):\n","            raise ValueError(\"Pooling should be one of ('max', 'avg'), got {}.\".format(pooling))\n","        pool = nn.AdaptiveAvgPool2d(1) if pooling == 'avg' else nn.AdaptiveMaxPool2d(1)\n","        flatten = Flatten()\n","        dropout = nn.Dropout(p=dropout, inplace=True) if dropout else nn.Identity()\n","        linear = nn.Linear(in_channels, classes, bias=True)\n","        activation = Activation(activation)\n","        super().__init__(pool, flatten, dropout, linear, activation)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.204624Z","iopub.status.busy":"2024-03-30T11:27:06.204395Z","iopub.status.idle":"2024-03-30T11:27:06.217293Z","shell.execute_reply":"2024-03-30T11:27:06.216506Z","shell.execute_reply.started":"2024-03-30T11:27:06.204604Z"},"trusted":true},"outputs":[],"source":["class Unet(SegmentationModel):\n","\n","    def __init__(\n","        self,\n","        encoder_name: str = \"resnet34\",\n","        encoder_depth: int = 5,\n","        encoder_weights: Optional[str] = \"imagenet\",\n","        decoder_use_batchnorm: bool = True,\n","        decoder_channels: List[int] = (256, 128, 64, 32, 16),\n","        decoder_attention_type: Optional[str] = None,\n","        in_channels: int = 3,\n","        classes: int = 1,\n","        activation: Optional[Union[str, callable]] = None,\n","        aux_params: Optional[dict] = None,\n","    ):\n","        super().__init__()\n","\n","        self.encoder = get_encoder(\n","            encoder_name,\n","            in_channels=in_channels,\n","            depth=encoder_depth,\n","            weights=encoder_weights,\n","        )\n","\n","        self.decoder = UnetDecoder(\n","            encoder_channels=self.encoder.out_channels,\n","            decoder_channels=decoder_channels,\n","            n_blocks=encoder_depth,\n","            use_batchnorm=decoder_use_batchnorm,\n","            center=True if encoder_name.startswith(\"vgg\") else False,\n","            attention_type=decoder_attention_type,\n","        )\n","\n","        self.segmentation_head = SegmentationHead(\n","            in_channels=decoder_channels[-1],\n","            out_channels=classes,\n","            activation=activation,\n","            kernel_size=3,\n","        )\n","\n","        if aux_params is not None:\n","            self.classification_head = ClassificationHead(\n","                in_channels=self.encoder.out_channels[-1], **aux_params\n","            )\n","        else:\n","            self.classification_head = None\n","\n","        self.name = \"u-{}\".format(encoder_name)\n","        self.initialize()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.218503Z","iopub.status.busy":"2024-03-30T11:27:06.218254Z","iopub.status.idle":"2024-03-30T11:27:06.232358Z","shell.execute_reply":"2024-03-30T11:27:06.231704Z","shell.execute_reply.started":"2024-03-30T11:27:06.218482Z"},"trusted":true},"outputs":[],"source":["class BaseObject(nn.Module):\n","\n","    def __init__(self, name=None):\n","        super().__init__()\n","        self._name = name\n","\n","    @property\n","    def __name__(self):\n","        if self._name is None:\n","            name = self.__class__.__name__\n","            s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n","            return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n","        else:\n","            return self._name\n","\n","\n","class Metric(BaseObject):\n","    pass\n","\n","\n","class Loss(BaseObject):\n","\n","    def __add__(self, other):\n","        if isinstance(other, Loss):\n","            return SumOfLosses(self, other)\n","        else:\n","            raise ValueError('Loss should be inherited from `Loss` class')\n","\n","    def __radd__(self, other):\n","        return self.__add__(other)\n","\n","    def __mul__(self, value):\n","        if isinstance(value, (int, float)):\n","            return MultipliedLoss(self, value)\n","        else:\n","            raise ValueError('Loss should be inherited from `BaseLoss` class')\n","\n","    def __rmul__(self, other):\n","        return self.__mul__(other)\n","\n","\n","class SumOfLosses(Loss):\n","\n","    def __init__(self, l1, l2):\n","        name = '{} + {}'.format(l1.__name__, l2.__name__)\n","        super().__init__(name=name)\n","        self.l1 = l1\n","        self.l2 = l2\n","\n","    def __call__(self, *inputs):\n","        return self.l1.forward(*inputs) + self.l2.forward(*inputs)\n","\n","\n","class MultipliedLoss(Loss):\n","\n","    def __init__(self, loss, multiplier):\n","\n","        # resolve name\n","        if len(loss.__name__.split('+')) > 1:\n","            name = '{} * ({})'.format(multiplier, loss.__name__)\n","        else:\n","            name = '{} * {}'.format(multiplier, loss.__name__)\n","        super().__init__(name=name)\n","        self.loss = loss\n","        self.multiplier = multiplier\n","\n","    def __call__(self, *inputs):\n","        return self.multiplier * self.loss.forward(*inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.233914Z","iopub.status.busy":"2024-03-30T11:27:06.233568Z","iopub.status.idle":"2024-03-30T11:27:06.251665Z","shell.execute_reply":"2024-03-30T11:27:06.250732Z","shell.execute_reply.started":"2024-03-30T11:27:06.233885Z"},"trusted":true},"outputs":[],"source":["def _take_channels(*xs, ignore_channels=None):\n","    if ignore_channels is None:\n","        return xs\n","    else:\n","        channels = [channel for channel in range(xs[0].shape[1]) if channel not in ignore_channels]\n","        xs = [torch.index_select(x, dim=1, index=torch.tensor(channels).to(x.device)) for x in xs]\n","        return xs\n","\n","\n","def _threshold(x, threshold=None):\n","    if threshold is not None:\n","        return (x > threshold).type(x.dtype)\n","    else:\n","        return x\n","\n","\n","def iou(pr, gt, eps=1e-7, threshold=None, ignore_channels=None):\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    intersection = torch.sum(gt * pr)\n","    union = torch.sum(gt) + torch.sum(pr) - intersection + eps\n","    return (intersection + eps) / union\n","\n","\n","jaccard = iou\n","\n","\n","def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, ignore_channels=None):\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt * pr)\n","    fp = torch.sum(pr) - tp\n","    fn = torch.sum(gt) - tp\n","\n","    score = ((1 + beta ** 2) * tp + eps) \\\n","            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + eps)\n","\n","    return score\n","\n","\n","def accuracy(pr, gt, threshold=0.5, ignore_channels=None):\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt == pr, dtype=pr.dtype)\n","    score = tp / gt.view(-1).shape[0]\n","    return score\n","\n","\n","def precision(pr, gt, eps=1e-7, threshold=None, ignore_channels=None):\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt * pr)\n","    fp = torch.sum(pr) - tp\n","\n","    score = (tp + eps) / (tp + fp + eps)\n","\n","    return score\n","\n","\n","def recall(pr, gt, eps=1e-7, threshold=None, ignore_channels=None):\n","    pr = _threshold(pr, threshold=threshold)\n","    pr, gt = _take_channels(pr, gt, ignore_channels=ignore_channels)\n","\n","    tp = torch.sum(gt * pr)\n","    fn = torch.sum(gt) - tp\n","\n","    score = (tp + eps) / (tp + fn + eps)\n","\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.252997Z","iopub.status.busy":"2024-03-30T11:27:06.252728Z","iopub.status.idle":"2024-03-30T11:27:06.266045Z","shell.execute_reply":"2024-03-30T11:27:06.265227Z","shell.execute_reply.started":"2024-03-30T11:27:06.252974Z"},"trusted":true},"outputs":[],"source":["class JaccardLoss(Loss):\n","\n","    def __init__(self, eps=1., activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return 1 - jaccard(\n","            y_pr, y_gt,\n","            eps=self.eps,\n","            threshold=None,\n","            ignore_channels=self.ignore_channels,\n","        )\n","\n","\n","class DiceLoss(Loss):\n","\n","    def __init__(self, eps=1., beta=1., activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.beta = beta\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return 1 - f_score(\n","            y_pr, y_gt,\n","            beta=self.beta,\n","            eps=self.eps,\n","            threshold=None,\n","            ignore_channels=self.ignore_channels,\n","        )\n","\n","\n","class L1Loss(nn.L1Loss, Loss):\n","    pass\n","\n","\n","class MSELoss(nn.MSELoss, Loss):\n","    pass\n","\n","\n","class CrossEntropyLoss(nn.CrossEntropyLoss, Loss):\n","    pass\n","\n","\n","class NLLLoss(nn.NLLLoss, Loss):\n","    pass\n","\n","\n","class BCELoss(nn.BCELoss, Loss):\n","    pass\n","\n","\n","class BCEWithLogitsLoss(nn.BCEWithLogitsLoss, Loss):\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.267496Z","iopub.status.busy":"2024-03-30T11:27:06.267247Z","iopub.status.idle":"2024-03-30T11:27:06.283719Z","shell.execute_reply":"2024-03-30T11:27:06.283082Z","shell.execute_reply.started":"2024-03-30T11:27:06.267475Z"},"trusted":true},"outputs":[],"source":["class IoU(Metric):\n","    __name__ = 'iou_score'\n","\n","    def __init__(self, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.threshold = threshold\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return iou(\n","            y_pr, y_gt,\n","            eps=self.eps,\n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        )\n","\n","\n","class Fscore(Metric):\n","\n","    def __init__(self, beta=1, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.beta = beta\n","        self.threshold = threshold\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return f_score(\n","            y_pr, y_gt,\n","            eps=self.eps,\n","            beta=self.beta,\n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        )\n","\n","\n","class Accuracy(Metric):\n","\n","    def __init__(self, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.threshold = threshold\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return accuracy(\n","            y_pr, y_gt,\n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        )\n","\n","\n","class Recall(Metric):\n","\n","    def __init__(self, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.threshold = threshold\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return F.recall(\n","            y_pr, y_gt,\n","            eps=self.eps,\n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        )\n","\n","\n","class Precision(Metric):\n","\n","    def __init__(self, eps=1e-7, threshold=0.5, activation=None, ignore_channels=None, **kwargs):\n","        super().__init__(**kwargs)\n","        self.eps = eps\n","        self.threshold = threshold\n","        self.activation = Activation(activation)\n","        self.ignore_channels = ignore_channels\n","\n","    def forward(self, y_pr, y_gt):\n","        y_pr = self.activation(y_pr)\n","        return F.precision(\n","            y_pr, y_gt,\n","            eps=self.eps,\n","            threshold=self.threshold,\n","            ignore_channels=self.ignore_channels,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.285058Z","iopub.status.busy":"2024-03-30T11:27:06.284731Z","iopub.status.idle":"2024-03-30T11:27:06.299321Z","shell.execute_reply":"2024-03-30T11:27:06.298672Z","shell.execute_reply.started":"2024-03-30T11:27:06.285029Z"},"trusted":true},"outputs":[],"source":["class Meter(object):\n","    def reset(self):\n","        pass\n","\n","    def add(self, value):\n","        pass\n","\n","    def value(self):\n","        pass\n","\n","\n","class AverageValueMeter(Meter):\n","    def __init__(self):\n","        super(AverageValueMeter, self).__init__()\n","        self.reset()\n","        self.val = 0\n","\n","    def add(self, value, n=1):\n","        self.val = value\n","        self.sum += value\n","        self.var += value * value\n","        self.n += n\n","\n","        if self.n == 0:\n","            self.mean, self.std = np.nan, np.nan\n","        elif self.n == 1:\n","            self.mean = 0.0 + self.sum  # This is to force a copy in torch/numpy\n","            self.std = np.inf\n","            self.mean_old = self.mean\n","            self.m_s = 0.0\n","        else:\n","            self.mean = self.mean_old + (value - n * self.mean_old) / float(self.n)\n","            self.m_s += (value - self.mean_old) * (value - self.mean)\n","            self.mean_old = self.mean\n","            self.std = np.sqrt(self.m_s / (self.n - 1.0))\n","\n","    def value(self):\n","        return self.mean, self.std\n","\n","    def reset(self):\n","        self.n = 0\n","        self.sum = 0.0\n","        self.var = 0.0\n","        self.val = 0.0\n","        self.mean = np.nan\n","        self.mean_old = 0.0\n","        self.m_s = 0.0\n","        self.std = np.nan"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.300626Z","iopub.status.busy":"2024-03-30T11:27:06.300319Z","iopub.status.idle":"2024-03-30T11:27:06.320280Z","shell.execute_reply":"2024-03-30T11:27:06.319420Z","shell.execute_reply.started":"2024-03-30T11:27:06.300603Z"},"trusted":true},"outputs":[],"source":["class Epoch:\n","\n","    def __init__(self, model, loss, metrics, stage_name, device='cpu', verbose=True):\n","        self.model = model\n","        self.loss = loss\n","        self.metrics = metrics\n","        self.stage_name = stage_name\n","        self.verbose = verbose\n","        self.device = device\n","\n","        self._to_device()\n","\n","    def _to_device(self):\n","        self.model.to(self.device)\n","        self.loss.to(self.device)\n","        for metric in self.metrics:\n","            metric.to(self.device)\n","\n","    def _format_logs(self, logs):\n","        str_logs = ['{} - {:.4}'.format(k, v) for k, v in logs.items()]\n","        s = ', '.join(str_logs)\n","        return s\n","\n","    def batch_update(self, x, y):\n","        raise NotImplementedError\n","\n","    def on_epoch_start(self):\n","        pass\n","\n","    def run(self, dataloader):\n","\n","        self.on_epoch_start()\n","\n","        logs = {}\n","        loss_meter = AverageValueMeter()\n","        metrics_meters = {metric.__name__: AverageValueMeter() for metric in self.metrics}\n","\n","        with tqdm(dataloader, desc=self.stage_name, file=sys.stdout, disable=not (self.verbose)) as iterator:\n","            for x, y in iterator:\n","                x, y = x.to(self.device), y.to(self.device)\n","                loss, y_pred = self.batch_update(x, y)\n","\n","                # update loss logs\n","                loss_value = loss.cpu().detach().numpy()\n","                loss_meter.add(loss_value)\n","                loss_logs = {self.loss.__name__: loss_meter.mean}\n","                logs.update(loss_logs)\n","\n","                # update metrics logs\n","                for metric_fn in self.metrics:\n","                    metric_value = metric_fn(y_pred, y).cpu().detach().numpy()\n","                    metrics_meters[metric_fn.__name__].add(metric_value)\n","                metrics_logs = {k: v.mean for k, v in metrics_meters.items()}\n","                logs.update(metrics_logs)\n","\n","                if self.verbose:\n","                    s = self._format_logs(logs)\n","                    iterator.set_postfix_str(s)\n","\n","        return logs\n","\n","\n","class TrainEpoch(Epoch):\n","\n","    def __init__(self, model, loss, metrics, optimizer, device='cpu', verbose=True):\n","        super().__init__(\n","            model=model,\n","            loss=loss,\n","            metrics=metrics,\n","            stage_name='train',\n","            device=device,\n","            verbose=verbose,\n","        )\n","        self.optimizer = optimizer\n","\n","    def on_epoch_start(self):\n","        self.model.train()\n","\n","    def batch_update(self, x, y):\n","        self.optimizer.zero_grad()\n","        prediction = self.model.forward(x)\n","        loss = self.loss(prediction, y)\n","        loss.backward()\n","        self.optimizer.step()\n","        return loss, prediction\n","\n","\n","class ValidEpoch(Epoch):\n","\n","    def __init__(self, model, loss, metrics, device='cpu', verbose=True):\n","        super().__init__(\n","            model=model,\n","            loss=loss,\n","            metrics=metrics,\n","            stage_name='valid',\n","            device=device,\n","            verbose=verbose,\n","        )\n","\n","    def on_epoch_start(self):\n","        self.model.eval()\n","\n","    def batch_update(self, x, y):\n","        with torch.no_grad():\n","            prediction = self.model.forward(x)\n","            loss = self.loss(prediction, y)\n","        return loss, prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.321771Z","iopub.status.busy":"2024-03-30T11:27:06.321513Z","iopub.status.idle":"2024-03-30T11:27:06.331600Z","shell.execute_reply":"2024-03-30T11:27:06.330885Z","shell.execute_reply.started":"2024-03-30T11:27:06.321748Z"},"trusted":true},"outputs":[],"source":["def visualize(**images):\n","    \"\"\"PLot images in one row.\"\"\"\n","    n = len(images)\n","    plt.figure(figsize=(16, 5))\n","    for i, (name, image) in enumerate(images.items()):\n","        plt.subplot(1, n, i + 1)\n","        plt.xticks([])\n","        plt.yticks([])\n","        plt.title(' '.join(name.split('_')).title())\n","        plt.imshow(image,cmap='binary')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.332893Z","iopub.status.busy":"2024-03-30T11:27:06.332425Z","iopub.status.idle":"2024-03-30T11:27:06.343482Z","shell.execute_reply":"2024-03-30T11:27:06.342662Z","shell.execute_reply.started":"2024-03-30T11:27:06.332870Z"},"trusted":true},"outputs":[],"source":["class Dataset(BaseDataset):\n","    def __init__(\n","            self, \n","            images_dir, \n","            masks_dir, \n","            classes=None, \n","            augmentation=None, \n","            preprocessing=None,\n","    ):\n","        self.ids = os.listdir(images_dir)\n","        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n","        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n","        self.augmentation = augmentation\n","        self.preprocessing = preprocessing\n","    \n","    def __getitem__(self, i):\n","        image = cv2.imread(self.images_fps[i])\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.masks_fps[i],0)\n","        ret,mask = cv2.threshold(mask,127,255,cv2.THRESH_BINARY_INV)\n","        mask = mask / 255.0\n","        mask.shape = mask.shape+(1,)\n","\n","        if self.augmentation:\n","            sample = self.augmentation(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","        \n","        if self.preprocessing:\n","            sample = self.preprocessing(image=image, mask=mask)\n","            image, mask = sample['image'], sample['mask']\n","            \n","        return image, mask\n","        \n","    def __len__(self):\n","        return len(self.ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.344805Z","iopub.status.busy":"2024-03-30T11:27:06.344499Z","iopub.status.idle":"2024-03-30T11:27:06.933135Z","shell.execute_reply":"2024-03-30T11:27:06.932296Z","shell.execute_reply.started":"2024-03-30T11:27:06.344782Z"},"trusted":true},"outputs":[],"source":["dataset = Dataset(x_train_dir, y_train_dir)\n","\n","image, mask = dataset[73] # get some sample\n","visualize(\n","    image=image, \n","    mask=mask.squeeze(),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.934605Z","iopub.status.busy":"2024-03-30T11:27:06.934344Z","iopub.status.idle":"2024-03-30T11:27:06.938733Z","shell.execute_reply":"2024-03-30T11:27:06.937897Z","shell.execute_reply.started":"2024-03-30T11:27:06.934582Z"},"trusted":true},"outputs":[],"source":["encoders = {}\n","encoders.update(efficient_net_encoders)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:06.940149Z","iopub.status.busy":"2024-03-30T11:27:06.939790Z","iopub.status.idle":"2024-03-30T11:27:08.695417Z","shell.execute_reply":"2024-03-30T11:27:08.694648Z","shell.execute_reply.started":"2024-03-30T11:27:06.940126Z"},"trusted":true},"outputs":[],"source":["DEVICE = 'cuda'\n","ENCODER = \"efficientnet-b5\"\n","ENCODER_WEIGHTS = 'imagenet'\n","model = Unet(\n","    encoder_name=ENCODER,\n","    encoder_depth=5, \n","    encoder_weights=ENCODER_WEIGHTS,\n","    decoder_use_batchnorm=True, \n","    decoder_channels=(512, 256, 128, 64, 32),\n","    decoder_attention_type='scse', \n","    in_channels=3,\n","    classes=1,\n","    activation='sigmoid', \n","    aux_params=None,\n",")\n","preprocessing_fn = get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:08.696771Z","iopub.status.busy":"2024-03-30T11:27:08.696488Z","iopub.status.idle":"2024-03-30T11:27:08.708266Z","shell.execute_reply":"2024-03-30T11:27:08.707387Z","shell.execute_reply.started":"2024-03-30T11:27:08.696747Z"},"trusted":true},"outputs":[],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:08.709595Z","iopub.status.busy":"2024-03-30T11:27:08.709301Z","iopub.status.idle":"2024-03-30T11:27:08.719315Z","shell.execute_reply":"2024-03-30T11:27:08.718496Z","shell.execute_reply.started":"2024-03-30T11:27:08.709571Z"},"trusted":true},"outputs":[],"source":["def to_tensor(x, **kwargs):\n","    return x.transpose(2, 0, 1).astype('float32')\n","\n","def get_preprocessing(preprocessing_fn):\n","\n","    _transform = [\n","        albu.Lambda(image=preprocessing_fn),\n","        albu.Lambda(image=to_tensor, mask=to_tensor),\n","    ]\n","    return albu.Compose(_transform)\n","\n","# def get_preprocessing():\n","\n","#     _transform = [\n","#         albu.Lambda(image=to_tensor, mask=to_tensor),\n","#     ]\n","#     return albu.Compose(_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:08.724445Z","iopub.status.busy":"2024-03-30T11:27:08.723952Z","iopub.status.idle":"2024-03-30T11:27:08.773301Z","shell.execute_reply":"2024-03-30T11:27:08.772634Z","shell.execute_reply.started":"2024-03-30T11:27:08.724421Z"},"trusted":true},"outputs":[],"source":["# train_dataset = Dataset(\n","#     x_train_dir, \n","#     y_train_dir, \n","#     augmentation=None, \n","#     preprocessing=get_preprocessing(),\n","# )\n","\n","# valid_dataset = Dataset(\n","#     x_valid_dir, \n","#     y_valid_dir, \n","#     augmentation=None, \n","#     preprocessing=get_preprocessing(),\n","# )\n","\n","train_dataset = Dataset(\n","    x_train_dir, \n","    y_train_dir, \n","    augmentation=None, \n","    preprocessing=get_preprocessing(preprocessing_fn),\n",")\n","\n","valid_dataset = Dataset(\n","    x_valid_dir, \n","    y_valid_dir, \n","    augmentation=None, \n","    preprocessing=get_preprocessing(preprocessing_fn),\n",")\n","\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n","valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True, num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:08.774551Z","iopub.status.busy":"2024-03-30T11:27:08.774296Z","iopub.status.idle":"2024-03-30T11:27:11.283306Z","shell.execute_reply":"2024-03-30T11:27:11.282527Z","shell.execute_reply.started":"2024-03-30T11:27:08.774530Z"},"trusted":true},"outputs":[],"source":["loss = DiceLoss()\n","metrics = [\n","    IoU(threshold=0.5),\n","]\n","\n","optimizer = torch.optim.Adam([ \n","    dict(params=model.parameters(), lr=0.0001),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:11.284924Z","iopub.status.busy":"2024-03-30T11:27:11.284460Z","iopub.status.idle":"2024-03-30T11:27:11.547953Z","shell.execute_reply":"2024-03-30T11:27:11.546682Z","shell.execute_reply.started":"2024-03-30T11:27:11.284891Z"},"trusted":true},"outputs":[],"source":["train_epoch = TrainEpoch(\n","    model, \n","    loss=loss, \n","    metrics=metrics, \n","    optimizer=optimizer,\n","    device=DEVICE,\n","    verbose=True,\n",")\n","\n","valid_epoch = ValidEpoch(\n","    model, \n","    loss=loss, \n","    metrics=metrics, \n","    device=DEVICE,\n","    verbose=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T11:27:11.549716Z","iopub.status.busy":"2024-03-30T11:27:11.549371Z","iopub.status.idle":"2024-03-30T12:09:54.748063Z","shell.execute_reply":"2024-03-30T12:09:54.746922Z","shell.execute_reply.started":"2024-03-30T11:27:11.549685Z"},"trusted":true},"outputs":[],"source":["epochs = 50\n","max_score = 0\n","iou_train = np.zeros(epochs)\n","loss_train = np.zeros(epochs)\n","iou_valid = np.zeros(epochs)\n","loss_valid = np.zeros(epochs)\n","\n","for i in range(0, epochs):\n","    \n","    print('\\nEpoch: {}'.format(i))\n","    train_logs = train_epoch.run(train_loader)\n","    valid_logs = valid_epoch.run(valid_loader)\n","    iou_train[i] = train_logs['iou_score']\n","    loss_train[i] = train_logs['dice_loss']\n","    iou_valid[i] = valid_logs['iou_score']\n","    loss_valid[i] = valid_logs['dice_loss']\n","    \n","    # do something (save model, change lr, etc.)\n","    if max_score < valid_logs['iou_score']:\n","        max_score = valid_logs['iou_score']\n","        torch.save(model, './best_model.pth')\n","        print('Model saved!')\n","        \n","    if i == 30:\n","        optimizer.param_groups[0]['lr'] = 1e-5\n","        print('Decrease decoder learning rate to 1e-5!')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:09:54.749693Z","iopub.status.busy":"2024-03-30T12:09:54.749412Z","iopub.status.idle":"2024-03-30T12:09:55.188377Z","shell.execute_reply":"2024-03-30T12:09:55.187580Z","shell.execute_reply.started":"2024-03-30T12:09:54.749664Z"},"trusted":true},"outputs":[],"source":["test_dataset = Dataset(\n","    x_test_dir, \n","    y_test_dir, \n","    augmentation=None, \n","    preprocessing=get_preprocessing(preprocessing_fn),\n","    #preprocessing=get_preprocessing()\n",")\n","\n","test1_dataset = Dataset(\n","    x_test_dir, \n","    y_test_dir, \n","    augmentation=None,\n",")\n","\n","best_model = torch.load('./best_model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:09:55.190251Z","iopub.status.busy":"2024-03-30T12:09:55.189880Z","iopub.status.idle":"2024-03-30T12:09:55.197540Z","shell.execute_reply":"2024-03-30T12:09:55.196529Z","shell.execute_reply.started":"2024-03-30T12:09:55.190213Z"},"trusted":true},"outputs":[],"source":["def myIoU(pre,label):\n","    matrix=pre+label\n","    TPFPFN=np.count_nonzero(matrix)\n","    TP=np.sum(matrix==2)\n","    iou=TP/TPFPFN\n","    return iou\n","\n","def myPrc(pre,label):\n","    matrix=pre+label\n","    TP=np.sum(matrix==2)\n","    TPFP=np.count_nonzero(pre)\n","    precision=TP/TPFP\n","    return precision\n","\n","def myRcl(pre,label):\n","    matrix=pre+label\n","    TP=np.sum(matrix==2)\n","    TPFN=np.count_nonzero(label)\n","    recall=TP/TPFN\n","    return recall"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T12:09:55.199582Z","iopub.status.busy":"2024-03-30T12:09:55.198703Z","iopub.status.idle":"2024-03-30T12:09:57.981175Z","shell.execute_reply":"2024-03-30T12:09:57.980272Z","shell.execute_reply.started":"2024-03-30T12:09:55.199550Z"},"trusted":true},"outputs":[],"source":["length=len(test_dataset)\n","IOU=0\n","Precision=0\n","Recall=0\n","for n in range(length):\n","    image, gt_mask = test_dataset[n]\n","    true_image,mask1 = test1_dataset[n]\n","    gt_mask = gt_mask.squeeze()\n","    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n","    pr_mask = best_model.predict(x_tensor)\n","    pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n","    IOU+=myIoU(pr_mask,gt_mask)\n","    Precision+=myPrc(pr_mask,gt_mask)\n","    Recall+=myRcl(pr_mask,gt_mask)\n","IOU=IOU/length\n","Precision=Precision/length\n","Recall=Recall/length\n","print('IoU =',IOU)\n","print('Precision =',Precision)\n","print('Recall =',Recall)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4602760,"sourceId":7849141,"sourceType":"datasetVersion"},{"datasetId":4692041,"sourceId":7973506,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
